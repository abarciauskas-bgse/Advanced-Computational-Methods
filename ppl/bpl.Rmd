---
title: "Bayesian Program Learning: MNIST Data Set"
author: "Aimee Barciauskas & Miquel Torrens"
date: "March 2, 2016"
output: pdf_document
---

# Bayesian Programming Learning on MNIST Dataset

The MNIST dataset of hand-drawn integers is comparable to the omniglot dataset of hand-drawn alphabetic characters in that it includes many examples with a high degree of variation. It is the variation across two-dimensions which makes the classification difficult. More explicitly, two vectors of a long series of pixels identifying the same character are very likely to be completely distinct.

For the MNIST dataset, we have simulated the process of the Bayesian Program Learning for the omniglot dataset for predicting new integers using a single example from each class 0-9.

One challenge in simulating this process directly is that the BPL paper used motor data from Amazon Turk: to create the program they used stroke trajectory data, e.g. each hand-drawn image came with trajectory data which informed where the strokes for each character were started and facilitated differentiation of distinct strokes and their relations to each other.

The MNIST dataset do not come with motor data so in what follows a "trajectory" is simulated by a directed-path-generating algorithm that relies highly on heuristics of how characters are drawn. The process here is also simplified by relying  entirely on the directed paths generated from the algorithm and has not incorporated the relations between strokes as part of assessing the posterior probability.

## The process is as follows:

**1. Create thinned image:** The original image is whittled down to a "one-pixel" skeleton
**2. Generate directed path:** Simulate trajectory using a heuristics-motivated path generating algorithm. [ADD ME: Describe how this works]

In theory, the directed path enables both new integer generation and integer prediction on test examples. Here we focus on the latter because it is cooler.

## 1. Creating the thinned image

```{r}
if (!require('grid')) install.packages('grid')
if (!require('prodlim')) install.packages('prodlim')
if (!require('igraph')) install.packages('igraph')
if (!require('RColorBrewer')) install.packages('RColorBrewer')
if (!require('scales')) install.packages('scales')
if (!require('MASS')) install.packages('MASS')

setwd('~/Box Sync/abarciausksas/myfiles/Advanced Computational Methods/data/')
digits <- read.csv('MNIST_training.csv')

# TODO: make package and put this stuff there
source('~/Box Sync/abarciausksas/myfiles/15D012 Advanced Computational Methods/datasets/MNIST/displayDigit.R')
source('~/Box Sync/abarciausksas/myfiles/Advanced Computational Methods/ppl/utils.R')
source('~/Box Sync/abarciausksas/myfiles/Advanced Computational Methods/ppl/thinPoints.R')
source('~/Box Sync/abarciausksas/myfiles/Advanced Computational Methods/ppl/allThinnedInts.R')

# Select a random subset of digits
rand.idcs <- sample(1:nrow(digits),100)
# special.set<-c(1765,2183,3251,1843,5043,2380,2520,5291,486,5079)
# rand.idcs <- c(special.set, rand.idcs)

for (i in 1:10) {
  digit <- digits[rand.idcs[i],]
  label <- as.numeric(digit[1])
  features <- as.numeric(digit[2:ncol(digit)])
  # displaying the original digit
  displayDigit(features, label, newDevice = FALSE)
  Sys.sleep(0.5)
}

# create the one-pixel skeleton
# [TODO] this takes 30 seconds so come up with something to talk about here
system.time(thinned.ints <- all.thinned.ints(digits[rand.idcs,]))
```

Make sure things worked:

```{r}
for (i in 1:length(rand.idcs)) {
  plot(thinned.ints[[i]]$points, main = paste0('Hey, this is a: ', thinned.ints[[i]]$label), pch = 19, ylim = c(-16,0), xlim = c(0,16))
  Sys.sleep(0.5)
}
```

With the thinned images, we generate a training set of the distinct set of 10 distinct integers.

```{r}
# Collect a training set
train.set <- list()
train.labels <- c()
train.idcs <- c()
# 
while (length(train.labels) < 10) {
  for (i in 1:length(rand.idcs)) {
    label <- thinned.ints[[i]]$label
    if (!(label %in% train.labels)) {
      train.idcs <- append(train.idcs, i)
      print(paste('Collected a:', label))
      train.labels <- append(train.labels, label)
      train.set <- append(train.set, list(thinned.ints[[i]]))
    }
  }
}

# Check on the training set
for (i in 1:length(train.set)) {
  plot(train.set[[i]]$points, main = paste0('Hey, this is a: ', train.set[[i]]$label), pch = 19, ylim = c(-16,0), xlim = c(0,16))
  Sys.sleep(0.5)
}
```

Collect a test set which is the other 90 integers from the random collection:

```{r}
# Set difference from random indices to get test set
test.idcs <- setdiff(1:length(rand.idcs), train.idcs)

# Collect the test set
test.set <- list()
test.labels <- c()
for (i in 1:length(test.idcs)) {
  i <- test.idcs[i]
  label <- thinned.ints[[i]]$label
  test.labels <- append(test.labels, label)
  test.set <- append(test.set, list(thinned.ints[[i]]))
}

for (i in 1:10) {
  plot(test.set[[i]]$points, main = paste0('Hey, this is a: ', test.set[[i]]$label), pch = 19, ylim = c(-16,0), xlim = c(0,16))
  Sys.sleep(0.5)
}
```

Generate paths and test resutls

```{r}
source('../ppl/addPaths.R')
source('../ppl/relativePosition.R')
source('../ppl/trainPath.R')
train.objects <- list()
for (i in 0:9) {
  digit <- train.set[[which(sapply(train.set, function(dig) { dig$label == i }))]]
  train.objects[[i+1]] <- train.digit(digit)
}

# ASSUMPTION: Normally distributed steps, strokes and changes in direction
total.steps.sd <- sd(sapply(train.objects, function(obj) { obj$total.steps }))
num.real.strokes.sd <- sd(sapply(train.objects, function(obj) { obj$num.real.strokes }))
# we use this below, if within distribution, increase likelihood
changes.sd <- sd(sapply(train.objects, function(obj) { obj$changes.in.direction }))

# create distribution of first major steps
# 
first.steps <- rep(0, 8)
for (i in 1:8) {
  first.steps[i] <- sum(sapply(train.objects, function(obj) {
    fs <- obj$first.major.step
    ifelse(is.na(fs), FALSE, fs == i)
  }))
}
first.steps.dist <- first.steps/10

# test objects
errors <- 0
for (i in 1:length(test.set)) {
  test.digit <- test.set[[i]]
  estimate <- train.digit(test.digit)

  # compare our test object with our training objects: e.g. predict the integer which has the most likely distribution of steps for the longest stroke, weighted by the difference it the length of the first stroke and weighted by the total number of strokes
  res <- lapply(train.objects, function(train.obj) {
    step.prob <- estimate$step.probs%*%train.obj$step.probs
    # probability given distribution of total steps for training object
    length.prob <- dnorm(abs(train.obj$total.steps - estimate$total.steps), mean = 0, sd = total.steps.sd)
    strokes.prob <- dnorm(abs(train.obj$num.real.strokes - estimate$num.real.strokes), mean = 0, sd = num.real.strokes.sd)
    changes.prob <- dnorm(abs(train.obj$changes.in.direction - estimate$changes.in.direction), mean = 0, sd = changes.sd)
    # if the first major step is the same, we want the probability of that major step given all the data 
    first.major.step.prob <- if ((!is.na(estimate$first.major.step)) &&
                                 (!is.na(train.obj$first.major.step)) &&
                                 (train.obj$first.major.step == estimate$first.major.step)) {
      first.steps.dist[estimate$first.major.step]
    } else {
      ifelse(is.na(estimate$first.major.step), 0.1, max(0.1*first.steps.dist[estimate$first.major.step], 0.1))
    }
    return(strokes.prob*first.major.step.prob*length.prob*changes.prob)
  })
  pred <- which.max(res)-1
  actual <- test.digit$label
  # random selection
  if (all(is.na(res))) {
    print('random selection')
    pred <- round(pred <- runif(1, min = 0, max = 9))
  }
  if (pred != actual) errors <- errors + 1
}
(accuracy <- 1-errors/length(test.set))
```


Compare with random selection

```{r}
(test.distribution <- matrix(append(c(0:9), rep(0,10)), nrow = 10, ncol = 2))
for (idx in 1:length(test.set)) {
  test.distribution[(test.set[[idx]]$label+1),2] <- test.distribution[(test.set[[idx]]$label+1),2] + 1
}
sum(test.distribution[,2])
barplot(test.distribution[,2])
apriori.test.probs <- test.distribution[,2]/length(test.set)
# do this 100 times to get average random accuracy
ntests <- 100
random.accuracies <- rep(0, ntests)
for (iter in 1:ntests) {
  random.draws <- which(rmultinom(length(test.set), size = 1, prob = apriori.test.probs) == 1, arr.ind = TRUE)[,1]
  #hist(random.draws)
  
  random.errors <- 0
  for (i in 1:length(test.set)) {
    if (test.set[[i]]$label != random.draws[i]) random.errors <- random.errors + 1
  }
  random.accuracies[iter] <- (random.accuracy <- 1 - random.errors/length(test.set))
}
mean(random.accuracies)
```
